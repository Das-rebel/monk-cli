# TreeQuest Configuration
# Monk CLI Enhanced - AI Engine Settings

# TreeQuest Engine Configuration
treequest:
  # Search depth and branching
  max_depth: 3                    # Maximum search depth for MCTS
  branching: 4                    # Number of branches per node
  rollout_budget: 32              # Number of rollout iterations
  
  # Cost and performance limits
  cost_cap_usd: 0.50             # Maximum cost per operation in USD
  timeout_seconds: 30             # Maximum execution time
  
  # Optimization objective
  objective: "quality"            # quality, latency, or cost
  
  # Caching settings
  cache_ttl_seconds: 3600        # Cache results for 1 hour
  enable_cache: true

# Model Registry Configuration
models:
  # OpenAI Models
  openai:
    gpt-4o:
      cost_per_1k_input: 0.005
      cost_per_1k_output: 0.015
      max_tokens: 128000
      capabilities: ["planner", "coder", "critic", "synthesizer"]
      latency_ms: 2000
      quality_score: 0.95
    
    gpt-4o-mini:
      cost_per_1k_input: 0.00015
      cost_per_1k_output: 0.0006
      max_tokens: 128000
      capabilities: ["planner", "coder", "critic"]
      latency_ms: 1000
      quality_score: 0.85
  
  # Anthropic Models
  anthropic:
    claude-3-opus:
      cost_per_1k_input: 0.015
      cost_per_1k_output: 0.075
      max_tokens: 200000
      capabilities: ["planner", "coder", "critic", "synthesizer"]
      latency_ms: 3000
      quality_score: 0.98
    
    claude-3-sonnet:
      cost_per_1k_input: 0.003
      cost_per_1k_output: 0.015
      max_tokens: 200000
      capabilities: ["planner", "coder", "critic"]
      latency_ms: 1500
      quality_score: 0.90
  
  # Mistral Models
  mistral:
    mistral-large:
      cost_per_1k_input: 0.007
      cost_per_1k_output: 0.024
      max_tokens: 32768
      capabilities: ["planner", "coder", "critic"]
      latency_ms: 2500
      quality_score: 0.88
  
  # Google Models
  google:
    gemini-pro:
      cost_per_1k_input: 0.0005
      cost_per_1k_output: 0.0015
      max_tokens: 1000000
      capabilities: ["planner", "coder", "critic"]
      latency_ms: 1800
      quality_score: 0.87

# Environment Variables (API Keys)
# Set these in your environment or .env file:
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here
# MISTRAL_API_KEY=your_mistral_key_here
# GOOGLE_API_KEY=your_google_key_here

# Default Model Selection
defaults:
  planner: "gpt-4o"              # High-level planning
  coder: "claude-3-sonnet"       # Code generation
  critic: "gpt-4o"               # Quality evaluation
  simulator: "gpt-4o-mini"       # Rollout simulation
  synthesizer: "claude-3-opus"   # Insight synthesis

# Performance Tuning
performance:
  parallel_simulations: 4         # Number of parallel simulations
  early_stopping: true            # Stop early if confidence is high
  adaptive_branching: true        # Adjust branching based on node quality
  cost_aware_selection: true      # Consider cost in model selection
